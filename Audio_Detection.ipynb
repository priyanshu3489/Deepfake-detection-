{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshu3489/Deepfake-detection-/blob/Deepfake-Audio-detection/Audio_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZxru_mE4cbY",
        "outputId": "6c920955-799b-4e0a-cfb1-1bc9eed518f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kA1U3TYYKFJv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qd0PxDbH6YP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev4G-sTmH9de",
        "outputId": "44d8ad38-464c-4b81-c497-59440cffd5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                          Audio Path  Label\n",
            "0  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      0\n",
            "1  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n",
            "2  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n",
            "3  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n",
            "4  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n"
          ]
        }
      ],
      "source": [
        "# Load the CSV file\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AVCeleb Dataset/Audio_dataset.csv')\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A8gN0CztSwi"
      },
      "source": [
        "# **Features extraction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waq1mafoII-F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d0f354b7-2095-4862-f599-7e486a5610eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7a878eb54744>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7a878eb54744>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Extracting MFCCs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmfccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_mfcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmfccs_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmfccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(y, sr, S, n_mfcc, dct_type, norm, lifter, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mS\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# multichannel behavior may be different due to relative noise floor differences between channels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpower_to_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m     M: np.ndarray = scipy.fftpack.dct(S, axis=-2, type=dct_type, norm=norm)[\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/feature/spectral.py\u001b[0m in \u001b[0;36mmelspectrogram\u001b[0;34m(y, sr, S, n_fft, hop_length, win_length, window, center, pad_mode, power, **kwargs)\u001b[0m\n\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m     \u001b[0;31m# Build a Mel filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m     \u001b[0mmel_basis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     \u001b[0mmelspec\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"...ft,mf->...mt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmel_basis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/filters.py\u001b[0m in \u001b[0;36mmel\u001b[0;34m(sr, n_fft, n_mels, fmin, fmax, htk, norm, dtype)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;31m# Only check weights if f_mel[0] is positive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# This means we have an empty channel somewhere\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         warnings.warn(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# avoid keyword arguments to speed up parsing, saves about 15%-20% for very\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# small reductions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[0m\u001b[1;32m     40\u001b[0m           initial=_NoValue, where=True):\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Function to extract features from an audio file\n",
        "def extract_features(audio_path):\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "    # Extracting Spectral Features\n",
        "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
        "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "\n",
        "    # Extracting MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "    # Combining all features into a single array\n",
        "    features = np.hstack([spectral_centroid, spectral_bandwidth, spectral_rolloff, mfccs_mean])\n",
        "    return features\n",
        "\n",
        "# Extract features and labels from the dataset\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    audio_path = row['Audio Path']\n",
        "    label = row['Label']\n",
        "    try:\n",
        "        features = extract_features(audio_path)\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hRvkafZeSmY"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csQNgCz8eWJt"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzfBjAPfehG5",
        "outputId": "f0c1566e-978c-48df-eed4-0dd3db873d0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.65163211 -1.7059233  -1.72474989 ... -0.75279753 -0.4525362\n",
            "   0.49507375]\n",
            " [ 0.44034824  0.87592452  0.1753081  ...  0.52524348 -1.04825447\n",
            "   1.10439904]\n",
            " [-0.53843954 -0.79202441 -0.56197439 ...  1.66955355  0.79039961\n",
            "   0.00736254]\n",
            " ...\n",
            " [-0.91508818 -1.07753709 -0.95244897 ...  0.88173803 -0.55235558\n",
            "  -0.90089081]\n",
            " [-0.84936162 -1.1730983  -0.86075213 ...  1.17890604  0.29802446\n",
            "  -0.31106326]\n",
            " [-0.77515468 -0.6711021  -0.80629701 ... -0.48959382 -1.38491365\n",
            "  -1.0271323 ]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ff3JlSTiemOf",
        "outputId": "409e2370-d9f9-47b4-9baa-763ddd227ae1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m28,736\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,122</span> (113.76 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,122\u001b[0m (113.76 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,122</span> (113.76 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,122\u001b[0m (113.76 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6901 - loss: 0.5823\n",
            "Epoch 1: val_loss improved from inf to 0.46212, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.6907 - loss: 0.5815 - val_accuracy: 0.7627 - val_loss: 0.4621\n",
            "Epoch 2/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7994 - loss: 0.4365\n",
            "Epoch 2: val_loss improved from 0.46212 to 0.43334, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7999 - loss: 0.4350 - val_accuracy: 0.7932 - val_loss: 0.4333\n",
            "Epoch 3/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8131 - loss: 0.4160\n",
            "Epoch 3: val_loss improved from 0.43334 to 0.39854, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.4136 - val_accuracy: 0.8203 - val_loss: 0.3985\n",
            "Epoch 4/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8184 - loss: 0.3950\n",
            "Epoch 4: val_loss improved from 0.39854 to 0.37803, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8194 - loss: 0.3940 - val_accuracy: 0.8322 - val_loss: 0.3780\n",
            "Epoch 5/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3680\n",
            "Epoch 5: val_loss improved from 0.37803 to 0.35754, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8452 - loss: 0.3682 - val_accuracy: 0.8576 - val_loss: 0.3575\n",
            "Epoch 6/100\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.3517\n",
            "Epoch 6: val_loss improved from 0.35754 to 0.34106, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8487 - loss: 0.3519 - val_accuracy: 0.8441 - val_loss: 0.3411\n",
            "Epoch 7/100\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8418 - loss: 0.3642\n",
            "Epoch 7: val_loss improved from 0.34106 to 0.33117, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8423 - loss: 0.3634 - val_accuracy: 0.8644 - val_loss: 0.3312\n",
            "Epoch 8/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8666 - loss: 0.3268\n",
            "Epoch 8: val_loss improved from 0.33117 to 0.33022, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8672 - loss: 0.3286 - val_accuracy: 0.8678 - val_loss: 0.3302\n",
            "Epoch 9/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.3092\n",
            "Epoch 9: val_loss improved from 0.33022 to 0.30859, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.3093 - val_accuracy: 0.8780 - val_loss: 0.3086\n",
            "Epoch 10/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8826 - loss: 0.3024\n",
            "Epoch 10: val_loss improved from 0.30859 to 0.30528, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.3028 - val_accuracy: 0.8831 - val_loss: 0.3053\n",
            "Epoch 11/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8612 - loss: 0.3269\n",
            "Epoch 11: val_loss improved from 0.30528 to 0.29549, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.3238 - val_accuracy: 0.8932 - val_loss: 0.2955\n",
            "Epoch 12/100\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8798 - loss: 0.3063\n",
            "Epoch 12: val_loss improved from 0.29549 to 0.29270, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8803 - loss: 0.3058 - val_accuracy: 0.8814 - val_loss: 0.2927\n",
            "Epoch 13/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 0.2992\n",
            "Epoch 13: val_loss improved from 0.29270 to 0.27900, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8826 - loss: 0.2990 - val_accuracy: 0.8831 - val_loss: 0.2790\n",
            "Epoch 14/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8957 - loss: 0.2568\n",
            "Epoch 14: val_loss improved from 0.27900 to 0.27121, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.2571 - val_accuracy: 0.8932 - val_loss: 0.2712\n",
            "Epoch 15/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.2704\n",
            "Epoch 15: val_loss improved from 0.27121 to 0.26919, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8973 - loss: 0.2705 - val_accuracy: 0.9085 - val_loss: 0.2692\n",
            "Epoch 16/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8924 - loss: 0.2624\n",
            "Epoch 16: val_loss improved from 0.26919 to 0.26419, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8924 - loss: 0.2624 - val_accuracy: 0.9034 - val_loss: 0.2642\n",
            "Epoch 17/100\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.2536\n",
            "Epoch 17: val_loss improved from 0.26419 to 0.25026, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8983 - loss: 0.2537 - val_accuracy: 0.9085 - val_loss: 0.2503\n",
            "Epoch 18/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8987 - loss: 0.2636\n",
            "Epoch 18: val_loss improved from 0.25026 to 0.24561, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8987 - loss: 0.2604 - val_accuracy: 0.9085 - val_loss: 0.2456\n",
            "Epoch 19/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2567\n",
            "Epoch 19: val_loss improved from 0.24561 to 0.23181, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.2544 - val_accuracy: 0.9136 - val_loss: 0.2318\n",
            "Epoch 20/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2236\n",
            "Epoch 20: val_loss did not improve from 0.23181\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2242 - val_accuracy: 0.9119 - val_loss: 0.2378\n",
            "Epoch 21/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2405\n",
            "Epoch 21: val_loss did not improve from 0.23181\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2408 - val_accuracy: 0.9102 - val_loss: 0.2368\n",
            "Epoch 22/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.2430\n",
            "Epoch 22: val_loss improved from 0.23181 to 0.22465, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.2404 - val_accuracy: 0.9186 - val_loss: 0.2247\n",
            "Epoch 23/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2440\n",
            "Epoch 23: val_loss improved from 0.22465 to 0.21572, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2438 - val_accuracy: 0.9237 - val_loss: 0.2157\n",
            "Epoch 24/100\n",
            "\u001b[1m49/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8978 - loss: 0.2593\n",
            "Epoch 24: val_loss did not improve from 0.21572\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.2497 - val_accuracy: 0.9186 - val_loss: 0.2268\n",
            "Epoch 25/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2331\n",
            "Epoch 25: val_loss improved from 0.21572 to 0.21402, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.2322 - val_accuracy: 0.9254 - val_loss: 0.2140\n",
            "Epoch 26/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9239 - loss: 0.2221\n",
            "Epoch 26: val_loss improved from 0.21402 to 0.20461, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9239 - loss: 0.2219 - val_accuracy: 0.9305 - val_loss: 0.2046\n",
            "Epoch 27/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2150\n",
            "Epoch 27: val_loss improved from 0.20461 to 0.20378, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9209 - loss: 0.2110 - val_accuracy: 0.9237 - val_loss: 0.2038\n",
            "Epoch 28/100\n",
            "\u001b[1m49/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2303\n",
            "Epoch 28: val_loss did not improve from 0.20378\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2229 - val_accuracy: 0.9237 - val_loss: 0.2089\n",
            "Epoch 29/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.2289\n",
            "Epoch 29: val_loss improved from 0.20378 to 0.19620, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9250 - loss: 0.2226 - val_accuracy: 0.9254 - val_loss: 0.1962\n",
            "Epoch 30/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9314 - loss: 0.1872\n",
            "Epoch 30: val_loss improved from 0.19620 to 0.18680, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.1872 - val_accuracy: 0.9356 - val_loss: 0.1868\n",
            "Epoch 31/100\n",
            "\u001b[1m49/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.2019\n",
            "Epoch 31: val_loss did not improve from 0.18680\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.2003 - val_accuracy: 0.9305 - val_loss: 0.1914\n",
            "Epoch 32/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.1729\n",
            "Epoch 32: val_loss did not improve from 0.18680\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9411 - loss: 0.1769 - val_accuracy: 0.9339 - val_loss: 0.1885\n",
            "Epoch 33/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9291 - loss: 0.1924\n",
            "Epoch 33: val_loss improved from 0.18680 to 0.18213, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 0.1923 - val_accuracy: 0.9475 - val_loss: 0.1821\n",
            "Epoch 34/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9391 - loss: 0.1699\n",
            "Epoch 34: val_loss improved from 0.18213 to 0.18063, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9391 - loss: 0.1701 - val_accuracy: 0.9373 - val_loss: 0.1806\n",
            "Epoch 35/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1708\n",
            "Epoch 35: val_loss did not improve from 0.18063\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9341 - loss: 0.1742 - val_accuracy: 0.9305 - val_loss: 0.1933\n",
            "Epoch 36/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1578\n",
            "Epoch 36: val_loss improved from 0.18063 to 0.17993, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.1644 - val_accuracy: 0.9322 - val_loss: 0.1799\n",
            "Epoch 37/100\n",
            "\u001b[1m49/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9412 - loss: 0.1864\n",
            "Epoch 37: val_loss did not improve from 0.17993\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9398 - loss: 0.1831 - val_accuracy: 0.9407 - val_loss: 0.1800\n",
            "Epoch 38/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9358 - loss: 0.1949\n",
            "Epoch 38: val_loss did not improve from 0.17993\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9362 - loss: 0.1853 - val_accuracy: 0.9271 - val_loss: 0.1842\n",
            "Epoch 39/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1489\n",
            "Epoch 39: val_loss improved from 0.17993 to 0.17244, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9473 - loss: 0.1551 - val_accuracy: 0.9390 - val_loss: 0.1724\n",
            "Epoch 40/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9470 - loss: 0.1481\n",
            "Epoch 40: val_loss did not improve from 0.17244\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9469 - loss: 0.1487 - val_accuracy: 0.9407 - val_loss: 0.1895\n",
            "Epoch 41/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.1537\n",
            "Epoch 41: val_loss did not improve from 0.17244\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.1584 - val_accuracy: 0.9390 - val_loss: 0.1816\n",
            "Epoch 42/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9389 - loss: 0.1751\n",
            "Epoch 42: val_loss improved from 0.17244 to 0.17118, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.1720 - val_accuracy: 0.9390 - val_loss: 0.1712\n",
            "Epoch 43/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9484 - loss: 0.1530\n",
            "Epoch 43: val_loss did not improve from 0.17118\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9456 - loss: 0.1538 - val_accuracy: 0.9305 - val_loss: 0.1743\n",
            "Epoch 44/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.1431\n",
            "Epoch 44: val_loss did not improve from 0.17118\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9518 - loss: 0.1477 - val_accuracy: 0.9339 - val_loss: 0.1793\n",
            "Epoch 45/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1513\n",
            "Epoch 45: val_loss improved from 0.17118 to 0.17032, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9488 - loss: 0.1515 - val_accuracy: 0.9356 - val_loss: 0.1703\n",
            "Epoch 46/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9563 - loss: 0.1282\n",
            "Epoch 46: val_loss did not improve from 0.17032\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.1352 - val_accuracy: 0.9407 - val_loss: 0.1718\n",
            "Epoch 47/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1381\n",
            "Epoch 47: val_loss improved from 0.17032 to 0.15733, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9541 - loss: 0.1382 - val_accuracy: 0.9458 - val_loss: 0.1573\n",
            "Epoch 48/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1315\n",
            "Epoch 48: val_loss did not improve from 0.15733\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9532 - loss: 0.1320 - val_accuracy: 0.9424 - val_loss: 0.1601\n",
            "Epoch 49/100\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9527 - loss: 0.1372\n",
            "Epoch 49: val_loss did not improve from 0.15733\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1375 - val_accuracy: 0.9475 - val_loss: 0.1600\n",
            "Epoch 50/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1411\n",
            "Epoch 50: val_loss did not improve from 0.15733\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9540 - loss: 0.1411 - val_accuracy: 0.9492 - val_loss: 0.1620\n",
            "Epoch 51/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1338\n",
            "Epoch 51: val_loss did not improve from 0.15733\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9459 - loss: 0.1339 - val_accuracy: 0.9305 - val_loss: 0.1644\n",
            "Epoch 52/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1376\n",
            "Epoch 52: val_loss improved from 0.15733 to 0.15294, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.1374 - val_accuracy: 0.9508 - val_loss: 0.1529\n",
            "Epoch 53/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.1561\n",
            "Epoch 53: val_loss did not improve from 0.15294\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9406 - loss: 0.1555 - val_accuracy: 0.9441 - val_loss: 0.1566\n",
            "Epoch 54/100\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1275\n",
            "Epoch 54: val_loss improved from 0.15294 to 0.14658, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9465 - loss: 0.1277 - val_accuracy: 0.9424 - val_loss: 0.1466\n",
            "Epoch 55/100\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9525 - loss: 0.1298\n",
            "Epoch 55: val_loss did not improve from 0.14658\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1301 - val_accuracy: 0.9373 - val_loss: 0.1676\n",
            "Epoch 56/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1193\n",
            "Epoch 56: val_loss did not improve from 0.14658\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9583 - loss: 0.1194 - val_accuracy: 0.9441 - val_loss: 0.1559\n",
            "Epoch 57/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1240\n",
            "Epoch 57: val_loss did not improve from 0.14658\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1239 - val_accuracy: 0.9475 - val_loss: 0.1519\n",
            "Epoch 58/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9640 - loss: 0.1089\n",
            "Epoch 58: val_loss did not improve from 0.14658\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.1091 - val_accuracy: 0.9441 - val_loss: 0.1571\n",
            "Epoch 59/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1201\n",
            "Epoch 59: val_loss did not improve from 0.14658\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1201 - val_accuracy: 0.9441 - val_loss: 0.1544\n",
            "Epoch 60/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1171\n",
            "Epoch 60: val_loss did not improve from 0.14658\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9581 - loss: 0.1181 - val_accuracy: 0.9492 - val_loss: 0.1597\n",
            "Epoch 61/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9581 - loss: 0.1137\n",
            "Epoch 61: val_loss did not improve from 0.14658\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1139 - val_accuracy: 0.9373 - val_loss: 0.1523\n",
            "Epoch 62/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.1246\n",
            "Epoch 62: val_loss improved from 0.14658 to 0.14373, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1206 - val_accuracy: 0.9492 - val_loss: 0.1437\n",
            "Epoch 63/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9680 - loss: 0.1102\n",
            "Epoch 63: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9679 - loss: 0.1103 - val_accuracy: 0.9373 - val_loss: 0.1759\n",
            "Epoch 64/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9601 - loss: 0.1471\n",
            "Epoch 64: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9599 - loss: 0.1398 - val_accuracy: 0.9559 - val_loss: 0.1542\n",
            "Epoch 65/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.1023\n",
            "Epoch 65: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9652 - loss: 0.1026 - val_accuracy: 0.9475 - val_loss: 0.1565\n",
            "Epoch 66/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9626 - loss: 0.1132\n",
            "Epoch 66: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9625 - loss: 0.1137 - val_accuracy: 0.9508 - val_loss: 0.1455\n",
            "Epoch 67/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1041\n",
            "Epoch 67: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.1065 - val_accuracy: 0.9407 - val_loss: 0.1550\n",
            "Epoch 68/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.1225\n",
            "Epoch 68: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9554 - loss: 0.1214 - val_accuracy: 0.9610 - val_loss: 0.1538\n",
            "Epoch 69/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1171\n",
            "Epoch 69: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9657 - loss: 0.1144 - val_accuracy: 0.9542 - val_loss: 0.1454\n",
            "Epoch 70/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1054\n",
            "Epoch 70: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9571 - loss: 0.1054 - val_accuracy: 0.9492 - val_loss: 0.1460\n",
            "Epoch 71/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1020\n",
            "Epoch 71: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.1020 - val_accuracy: 0.9593 - val_loss: 0.1464\n",
            "Epoch 72/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0953\n",
            "Epoch 72: val_loss did not improve from 0.14373\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9684 - loss: 0.0960 - val_accuracy: 0.9508 - val_loss: 0.1606\n",
            "Epoch 72: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Model training\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n",
        "    ModelCheckpoint('deepfake_audio_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B81n1Ttwetj1",
        "outputId": "30889d2e-3af2-4396-a865-e8d4d78f80ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the entire model for future use\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/deepfake_audio_detection_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "7ntmllmIh4ft",
        "outputId": "07eb854f-8aea-4bbd-ee05-47a6186793a3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1021\n",
            "           1       0.98      0.99      0.98      1335\n",
            "\n",
            "    accuracy                           0.98      2356\n",
            "   macro avg       0.98      0.98      0.98      2356\n",
            "weighted avg       0.98      0.98      0.98      2356\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.models import load_model\n",
        "# Import seaborn for visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load the model\n",
        "model = load_model('deepfake_audio_model.h5')\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred = model.predict(X_train)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Convert class names to strings if necessary\n",
        "target_names = [str(cls) for cls in label_encoder.classes_]\n",
        "\n",
        "# Calculate and print evaluation metrics\n",
        "print(classification_report(y_true, y_pred_classes, target_names=target_names))\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "id": "iQAM_AjFfdNR",
        "outputId": "a3b8da24-4aa2-416a-fb80-4363fcc0e8aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1021\n",
            "           1       0.98      0.99      0.98      1335\n",
            "\n",
            "    accuracy                           0.98      2356\n",
            "   macro avg       0.98      0.98      0.98      2356\n",
            "weighted avg       0.98      0.98      0.98      2356\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import seaborn for visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Correcting the target names by converting them to strings\n",
        "target_names = label_encoder.classes_.astype(str)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "print(classification_report(y_true, y_pred_classes, target_names=target_names))\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9Yviy4G3gA_"
      },
      "source": [
        "## Correction code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64fCESOVeuXA",
        "outputId": "f0b87404-a71b-4385-c8c4-af813c072da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ULqpbKe3fw6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle  # For saving and loading scaler and label encoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9xH15wK4rUk",
        "outputId": "a07d1d39-2d32-4db8-95fb-ddc7f115f545"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                          Audio Path  Label\n",
            "0  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      0\n",
            "1  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n",
            "2  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n",
            "3  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n",
            "4  /content/drive/MyDrive/Colab Notebooks/AVCeleb...      1\n"
          ]
        }
      ],
      "source": [
        "# Load the CSV file\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/AVCeleb Dataset/Audio_dataset.csv')  # Adjusted to the uploaded path\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu2fW-RR46Fz"
      },
      "outputs": [],
      "source": [
        "# Function to extract features from an audio file\n",
        "def extract_features(audio_path):\n",
        "    y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "    # Extracting Spectral Features\n",
        "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
        "    spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))\n",
        "\n",
        "    # Extracting MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "    # Combining all features into a single array\n",
        "    features = np.hstack([spectral_centroid, spectral_bandwidth, spectral_rolloff, mfccs_mean])\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Tiu7gO849P8"
      },
      "outputs": [],
      "source": [
        "# Extract features and labels from the dataset\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for index, row in data.iterrows():\n",
        "    audio_path = row['Audio Path']\n",
        "    label = row['Label']\n",
        "    try:\n",
        "        features = extract_features(audio_path)\n",
        "        X.append(features)\n",
        "        y.append(label)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio_path}: {e}\")\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "y_categorical = to_categorical(y_encoded)\n",
        "\n",
        "# Save the label encoder\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaler\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "JTT29NY15Fw3",
        "outputId": "df76f92d-a60a-453b-ddf9-b92a6e9df8c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">28,736</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m448\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m28,736\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,122</span> (113.76 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29,122\u001b[0m (113.76 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29,122</span> (113.76 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29,122\u001b[0m (113.76 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6908 - loss: 0.5760\n",
            "Epoch 1: val_loss improved from inf to 0.45041, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 29ms/step - accuracy: 0.6915 - loss: 0.5752 - val_accuracy: 0.7847 - val_loss: 0.4504\n",
            "Epoch 2/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8089 - loss: 0.4287\n",
            "Epoch 2: val_loss improved from 0.45041 to 0.41097, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8091 - loss: 0.4285 - val_accuracy: 0.8254 - val_loss: 0.4110\n",
            "Epoch 3/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.3966\n",
            "Epoch 3: val_loss improved from 0.41097 to 0.38970, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8237 - loss: 0.3994 - val_accuracy: 0.8390 - val_loss: 0.3897\n",
            "Epoch 4/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.3762\n",
            "Epoch 4: val_loss improved from 0.38970 to 0.36785, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8445 - loss: 0.3762 - val_accuracy: 0.8305 - val_loss: 0.3678\n",
            "Epoch 5/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8454 - loss: 0.3710\n",
            "Epoch 5: val_loss improved from 0.36785 to 0.35331, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8440 - loss: 0.3677 - val_accuracy: 0.8508 - val_loss: 0.3533\n",
            "Epoch 6/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8467 - loss: 0.3590\n",
            "Epoch 6: val_loss improved from 0.35331 to 0.33501, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8524 - loss: 0.3530 - val_accuracy: 0.8492 - val_loss: 0.3350\n",
            "Epoch 7/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8384 - loss: 0.3649\n",
            "Epoch 7: val_loss improved from 0.33501 to 0.32755, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8415 - loss: 0.3608 - val_accuracy: 0.8661 - val_loss: 0.3275\n",
            "Epoch 8/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8595 - loss: 0.3430\n",
            "Epoch 8: val_loss improved from 0.32755 to 0.32506, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8595 - loss: 0.3427 - val_accuracy: 0.8729 - val_loss: 0.3251\n",
            "Epoch 9/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.2994\n",
            "Epoch 9: val_loss improved from 0.32506 to 0.29630, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.3050 - val_accuracy: 0.8864 - val_loss: 0.2963\n",
            "Epoch 10/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.3041\n",
            "Epoch 10: val_loss improved from 0.29630 to 0.29129, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8747 - loss: 0.3035 - val_accuracy: 0.8983 - val_loss: 0.2913\n",
            "Epoch 11/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.3023\n",
            "Epoch 11: val_loss improved from 0.29129 to 0.29058, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8685 - loss: 0.3023 - val_accuracy: 0.9017 - val_loss: 0.2906\n",
            "Epoch 12/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.2987\n",
            "Epoch 12: val_loss improved from 0.29058 to 0.28415, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8745 - loss: 0.2971 - val_accuracy: 0.8831 - val_loss: 0.2841\n",
            "Epoch 13/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.2709\n",
            "Epoch 13: val_loss improved from 0.28415 to 0.26630, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8995 - loss: 0.2718 - val_accuracy: 0.9119 - val_loss: 0.2663\n",
            "Epoch 14/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.2715\n",
            "Epoch 14: val_loss improved from 0.26630 to 0.25470, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.2727 - val_accuracy: 0.9017 - val_loss: 0.2547\n",
            "Epoch 15/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.2603\n",
            "Epoch 15: val_loss did not improve from 0.25470\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.2606 - val_accuracy: 0.9102 - val_loss: 0.2547\n",
            "Epoch 16/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.2882\n",
            "Epoch 16: val_loss improved from 0.25470 to 0.24689, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8953 - loss: 0.2844 - val_accuracy: 0.9068 - val_loss: 0.2469\n",
            "Epoch 17/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2480\n",
            "Epoch 17: val_loss improved from 0.24689 to 0.24387, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.2464 - val_accuracy: 0.9085 - val_loss: 0.2439\n",
            "Epoch 18/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2357\n",
            "Epoch 18: val_loss did not improve from 0.24387\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2388 - val_accuracy: 0.9119 - val_loss: 0.2495\n",
            "Epoch 19/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2462\n",
            "Epoch 19: val_loss did not improve from 0.24387\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2473 - val_accuracy: 0.9000 - val_loss: 0.2444\n",
            "Epoch 20/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2359\n",
            "Epoch 20: val_loss improved from 0.24387 to 0.22627, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2346 - val_accuracy: 0.9034 - val_loss: 0.2263\n",
            "Epoch 21/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2116\n",
            "Epoch 21: val_loss improved from 0.22627 to 0.21756, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2175 - val_accuracy: 0.9186 - val_loss: 0.2176\n",
            "Epoch 22/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9226 - loss: 0.2186\n",
            "Epoch 22: val_loss did not improve from 0.21756\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9224 - loss: 0.2188 - val_accuracy: 0.9237 - val_loss: 0.2187\n",
            "Epoch 23/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2361\n",
            "Epoch 23: val_loss improved from 0.21756 to 0.21689, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2355 - val_accuracy: 0.9220 - val_loss: 0.2169\n",
            "Epoch 24/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1871\n",
            "Epoch 24: val_loss improved from 0.21689 to 0.20982, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9335 - loss: 0.1968 - val_accuracy: 0.9237 - val_loss: 0.2098\n",
            "Epoch 25/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.2028\n",
            "Epoch 25: val_loss improved from 0.20982 to 0.20433, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9280 - loss: 0.2028 - val_accuracy: 0.9186 - val_loss: 0.2043\n",
            "Epoch 26/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.1929\n",
            "Epoch 26: val_loss did not improve from 0.20433\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.1934 - val_accuracy: 0.9102 - val_loss: 0.2196\n",
            "Epoch 27/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.2350\n",
            "Epoch 27: val_loss did not improve from 0.20433\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.2273 - val_accuracy: 0.9220 - val_loss: 0.2133\n",
            "Epoch 28/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.1992\n",
            "Epoch 28: val_loss improved from 0.20433 to 0.19499, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9276 - loss: 0.1995 - val_accuracy: 0.9237 - val_loss: 0.1950\n",
            "Epoch 29/100\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2145\n",
            "Epoch 29: val_loss improved from 0.19499 to 0.18889, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9321 - loss: 0.2132 - val_accuracy: 0.9220 - val_loss: 0.1889\n",
            "Epoch 30/100\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.1838\n",
            "Epoch 30: val_loss improved from 0.18889 to 0.18743, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.1834 - val_accuracy: 0.9288 - val_loss: 0.1874\n",
            "Epoch 31/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.1972\n",
            "Epoch 31: val_loss did not improve from 0.18743\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.1943 - val_accuracy: 0.9288 - val_loss: 0.2008\n",
            "Epoch 32/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2019\n",
            "Epoch 32: val_loss did not improve from 0.18743\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9237 - loss: 0.2017 - val_accuracy: 0.9254 - val_loss: 0.1892\n",
            "Epoch 33/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1741\n",
            "Epoch 33: val_loss did not improve from 0.18743\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1740 - val_accuracy: 0.9237 - val_loss: 0.1898\n",
            "Epoch 34/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1793\n",
            "Epoch 34: val_loss improved from 0.18743 to 0.18031, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9357 - loss: 0.1812 - val_accuracy: 0.9390 - val_loss: 0.1803\n",
            "Epoch 35/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1608\n",
            "Epoch 35: val_loss did not improve from 0.18031\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9343 - loss: 0.1612 - val_accuracy: 0.9322 - val_loss: 0.1958\n",
            "Epoch 36/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9288 - loss: 0.1964\n",
            "Epoch 36: val_loss improved from 0.18031 to 0.17957, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9291 - loss: 0.1959 - val_accuracy: 0.9271 - val_loss: 0.1796\n",
            "Epoch 37/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9425 - loss: 0.1707\n",
            "Epoch 37: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9417 - loss: 0.1709 - val_accuracy: 0.9220 - val_loss: 0.1880\n",
            "Epoch 38/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9407 - loss: 0.1862\n",
            "Epoch 38: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9407 - loss: 0.1822 - val_accuracy: 0.9271 - val_loss: 0.1819\n",
            "Epoch 39/100\n",
            "\u001b[1m53/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.1586\n",
            "Epoch 39: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9394 - loss: 0.1627 - val_accuracy: 0.9322 - val_loss: 0.1819\n",
            "Epoch 40/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9415 - loss: 0.1488\n",
            "Epoch 40: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.1525 - val_accuracy: 0.9339 - val_loss: 0.1853\n",
            "Epoch 41/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9539 - loss: 0.1552\n",
            "Epoch 41: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9510 - loss: 0.1570 - val_accuracy: 0.9220 - val_loss: 0.1954\n",
            "Epoch 42/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1662\n",
            "Epoch 42: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9466 - loss: 0.1655 - val_accuracy: 0.9288 - val_loss: 0.1893\n",
            "Epoch 43/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.1566\n",
            "Epoch 43: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9393 - loss: 0.1567 - val_accuracy: 0.9271 - val_loss: 0.1807\n",
            "Epoch 44/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1359\n",
            "Epoch 44: val_loss did not improve from 0.17957\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.1418 - val_accuracy: 0.9271 - val_loss: 0.1922\n",
            "Epoch 45/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.1703\n",
            "Epoch 45: val_loss improved from 0.17957 to 0.17420, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9413 - loss: 0.1697 - val_accuracy: 0.9356 - val_loss: 0.1742\n",
            "Epoch 46/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.1774\n",
            "Epoch 46: val_loss did not improve from 0.17420\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.1736 - val_accuracy: 0.9407 - val_loss: 0.1766\n",
            "Epoch 47/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9467 - loss: 0.1525\n",
            "Epoch 47: val_loss did not improve from 0.17420\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.1525 - val_accuracy: 0.9339 - val_loss: 0.1775\n",
            "Epoch 48/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1470\n",
            "Epoch 48: val_loss improved from 0.17420 to 0.17071, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9469 - loss: 0.1454 - val_accuracy: 0.9390 - val_loss: 0.1707\n",
            "Epoch 49/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1213\n",
            "Epoch 49: val_loss did not improve from 0.17071\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1263 - val_accuracy: 0.9373 - val_loss: 0.1740\n",
            "Epoch 50/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.1336\n",
            "Epoch 50: val_loss did not improve from 0.17071\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9593 - loss: 0.1337 - val_accuracy: 0.9356 - val_loss: 0.1743\n",
            "Epoch 51/100\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1248\n",
            "Epoch 51: val_loss did not improve from 0.17071\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9567 - loss: 0.1259 - val_accuracy: 0.9356 - val_loss: 0.1757\n",
            "Epoch 52/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1231\n",
            "Epoch 52: val_loss did not improve from 0.17071\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9598 - loss: 0.1233 - val_accuracy: 0.9356 - val_loss: 0.1715\n",
            "Epoch 53/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9464 - loss: 0.1510\n",
            "Epoch 53: val_loss did not improve from 0.17071\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9491 - loss: 0.1440 - val_accuracy: 0.9441 - val_loss: 0.1760\n",
            "Epoch 54/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9552 - loss: 0.1299\n",
            "Epoch 54: val_loss did not improve from 0.17071\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9550 - loss: 0.1303 - val_accuracy: 0.9339 - val_loss: 0.1828\n",
            "Epoch 55/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1181\n",
            "Epoch 55: val_loss improved from 0.17071 to 0.17004, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9571 - loss: 0.1182 - val_accuracy: 0.9390 - val_loss: 0.1700\n",
            "Epoch 56/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1237\n",
            "Epoch 56: val_loss improved from 0.17004 to 0.16495, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9519 - loss: 0.1278 - val_accuracy: 0.9356 - val_loss: 0.1650\n",
            "Epoch 57/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9540 - loss: 0.1384\n",
            "Epoch 57: val_loss did not improve from 0.16495\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9526 - loss: 0.1422 - val_accuracy: 0.9424 - val_loss: 0.1722\n",
            "Epoch 58/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9567 - loss: 0.1369\n",
            "Epoch 58: val_loss did not improve from 0.16495\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9559 - loss: 0.1370 - val_accuracy: 0.9373 - val_loss: 0.1778\n",
            "Epoch 59/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9495 - loss: 0.1218\n",
            "Epoch 59: val_loss did not improve from 0.16495\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1247 - val_accuracy: 0.9407 - val_loss: 0.1703\n",
            "Epoch 60/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9523 - loss: 0.1256\n",
            "Epoch 60: val_loss did not improve from 0.16495\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9528 - loss: 0.1270 - val_accuracy: 0.9424 - val_loss: 0.1751\n",
            "Epoch 61/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9597 - loss: 0.1175\n",
            "Epoch 61: val_loss improved from 0.16495 to 0.16261, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9597 - loss: 0.1174 - val_accuracy: 0.9458 - val_loss: 0.1626\n",
            "Epoch 62/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9526 - loss: 0.1166\n",
            "Epoch 62: val_loss did not improve from 0.16261\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9531 - loss: 0.1203 - val_accuracy: 0.9441 - val_loss: 0.1660\n",
            "Epoch 63/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9603 - loss: 0.1214\n",
            "Epoch 63: val_loss improved from 0.16261 to 0.15343, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9601 - loss: 0.1190 - val_accuracy: 0.9492 - val_loss: 0.1534\n",
            "Epoch 64/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.1246\n",
            "Epoch 64: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9580 - loss: 0.1243 - val_accuracy: 0.9441 - val_loss: 0.1560\n",
            "Epoch 65/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1129\n",
            "Epoch 65: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.1157 - val_accuracy: 0.9373 - val_loss: 0.1610\n",
            "Epoch 66/100\n",
            "\u001b[1m68/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9632 - loss: 0.1258\n",
            "Epoch 66: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9631 - loss: 0.1255 - val_accuracy: 0.9458 - val_loss: 0.1597\n",
            "Epoch 67/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1157\n",
            "Epoch 67: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9620 - loss: 0.1156 - val_accuracy: 0.9475 - val_loss: 0.1614\n",
            "Epoch 68/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9589 - loss: 0.1110\n",
            "Epoch 68: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9589 - loss: 0.1109 - val_accuracy: 0.9441 - val_loss: 0.1596\n",
            "Epoch 69/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9653 - loss: 0.1063\n",
            "Epoch 69: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9653 - loss: 0.1063 - val_accuracy: 0.9458 - val_loss: 0.1585\n",
            "Epoch 70/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9614 - loss: 0.1248\n",
            "Epoch 70: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.1248 - val_accuracy: 0.9424 - val_loss: 0.1709\n",
            "Epoch 71/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9628 - loss: 0.1075\n",
            "Epoch 71: val_loss did not improve from 0.15343\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1076 - val_accuracy: 0.9475 - val_loss: 0.1569\n",
            "Epoch 72/100\n",
            "\u001b[1m71/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9631 - loss: 0.1106\n",
            "Epoch 72: val_loss improved from 0.15343 to 0.15306, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1108 - val_accuracy: 0.9424 - val_loss: 0.1531\n",
            "Epoch 73/100\n",
            "\u001b[1m70/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9670 - loss: 0.1037\n",
            "Epoch 73: val_loss improved from 0.15306 to 0.14274, saving model to deepfake_audio_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1043 - val_accuracy: 0.9559 - val_loss: 0.1427\n",
            "Epoch 74/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9601 - loss: 0.1069\n",
            "Epoch 74: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9612 - loss: 0.1058 - val_accuracy: 0.9559 - val_loss: 0.1439\n",
            "Epoch 75/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9634 - loss: 0.1065\n",
            "Epoch 75: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9634 - loss: 0.1065 - val_accuracy: 0.9525 - val_loss: 0.1534\n",
            "Epoch 76/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9719 - loss: 0.0928\n",
            "Epoch 76: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.0934 - val_accuracy: 0.9559 - val_loss: 0.1467\n",
            "Epoch 77/100\n",
            "\u001b[1m51/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0880\n",
            "Epoch 77: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9715 - loss: 0.0924 - val_accuracy: 0.9542 - val_loss: 0.1573\n",
            "Epoch 78/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9679 - loss: 0.1005\n",
            "Epoch 78: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9677 - loss: 0.1007 - val_accuracy: 0.9525 - val_loss: 0.1589\n",
            "Epoch 79/100\n",
            "\u001b[1m73/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9647 - loss: 0.1018\n",
            "Epoch 79: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.1019 - val_accuracy: 0.9407 - val_loss: 0.1533\n",
            "Epoch 80/100\n",
            "\u001b[1m52/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.0881\n",
            "Epoch 80: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9658 - loss: 0.0913 - val_accuracy: 0.9475 - val_loss: 0.1715\n",
            "Epoch 81/100\n",
            "\u001b[1m50/74\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9665 - loss: 0.0813\n",
            "Epoch 81: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0856 - val_accuracy: 0.9525 - val_loss: 0.1609\n",
            "Epoch 82/100\n",
            "\u001b[1m72/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1081\n",
            "Epoch 82: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9601 - loss: 0.1077 - val_accuracy: 0.9475 - val_loss: 0.1637\n",
            "Epoch 83/100\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9660 - loss: 0.0933\n",
            "Epoch 83: val_loss did not improve from 0.14274\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.0933 - val_accuracy: 0.9492 - val_loss: 0.1563\n",
            "Epoch 83: early stopping\n"
          ]
        }
      ],
      "source": [
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Model training\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min'),\n",
        "    ModelCheckpoint('deepfake_audio_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=callbacks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M3IY1vzm5fJE",
        "outputId": "79aa05db-6d36-40df-eb3d-8ad0d4f90d09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save the entire model for future use\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/deepfake_audio_detection_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2SNrFFi-5dgB",
        "outputId": "ff25ffd2-6eb1-4802-8f41-137ac7a84c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1021\n",
            "           1       0.99      0.99      0.99      1335\n",
            "\n",
            "    accuracy                           0.99      2356\n",
            "   macro avg       0.99      0.99      0.99      2356\n",
            "weighted avg       0.99      0.99      0.99      2356\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate on the training set\n",
        "y_pred = model.predict(X_train)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_train, axis=1)\n",
        "\n",
        "# Convert class names to strings if necessary\n",
        "target_names = [str(cls) for cls in label_encoder.classes_]\n",
        "\n",
        "# Calculate and print evaluation metrics\n",
        "print(classification_report(y_true, y_pred_classes, target_names=target_names))\n",
        "\n",
        "# Generate confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=target_names, yticklabels=target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH9XSxbgdtCA"
      },
      "source": [
        "# Prediction code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6HJNMgq3Gtkr",
        "outputId": "5792b437-e64c-4e72-b1b2-0a5c437d1d8c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step\n",
            "The predicted label for the external audio is: 0\n"
          ]
        }
      ],
      "source": [
        "# Function to predict and label external audio files\n",
        "def predict_external_audio(model_path, scaler_path, label_encoder_path, audio_path):\n",
        "    # Load the trained model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Load the scaler and label encoder\n",
        "    with open(scaler_path, 'rb') as f:\n",
        "        scaler = pickle.load(f)\n",
        "    with open(label_encoder_path, 'rb') as f:\n",
        "        label_encoder = pickle.load(f)\n",
        "\n",
        "    # Extract features from the external audio file\n",
        "    features = extract_features(audio_path)\n",
        "\n",
        "    # Scale the features\n",
        "    features_scaled = scaler.transform([features])\n",
        "\n",
        "    # Add a dimension for the Conv1D model\n",
        "    features_scaled = np.expand_dims(features_scaled, axis=2)\n",
        "\n",
        "    # Predict the class\n",
        "    prediction = model.predict(features_scaled)\n",
        "    predicted_class = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Retrieve the label from the encoder\n",
        "    predicted_label = label_encoder.inverse_transform([predicted_class])[0]\n",
        "\n",
        "    return predicted_label\n",
        "\n",
        "# Example usage of predict_external_audio\n",
        "external_audio_path = '/content/drive/MyDrive/Colab Notebooks/ElevenLabs_2025-02-22T18_06_27_Rachel_pre_s50_sb75_se0_b_m2.mp3'\n",
        "predicted_label = predict_external_audio(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/deepfake_audio_detection_model.h5',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/scaler.pkl',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/label_encoder.pkl',\n",
        "    external_audio_path\n",
        ")\n",
        "print(f'The predicted label for the external audio is: {predicted_label}')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V5E1",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}